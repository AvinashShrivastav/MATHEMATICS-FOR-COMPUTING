# -*- coding: utf-8 -*-
"""numpy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/155cZliTxFGKWJJBXtmEGujUSgXhW3Dqr
"""

#diagonizable property
import numpy as np

# Define the matrix
A = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]])

# Find the eigenvalues and eigenvectors
eigvals, eigvecs = np.linalg.eig(A)

# Check if the matrix is diagonalizable
if np.linalg.matrix_rank(eigvecs) == A.shape[0]:
    print("The matrix is diagonalizable")
else:
    print("The matrix is not diagonalizable")

# Print the eigenvalues and eigenvectors
print("Eigenvalues:", eigvals)
print("Eigenvectors:", eigvecs)


#Cayley-Hamilton theorem 

import numpy as np

# Define the matrix
A = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]])

# Find the eigenvalues and eigenvectors
eigvals, eigvecs = np.linalg.eig(A)

# Compute the characteristic polynomial
poly = np.poly1d([1, -np.sum(eigvals), np.linalg.det(A)])
print("Characteristic polynomial:", poly)

# Evaluate the polynomial at A
result = poly(A)
print("Result of polynomial evaluated at A:\n", result)

#gradient of a scalar field
import numpy as np

# Define the scalar field
def f(x, y, z):
    return np.sin(x) * np.cos(y) * np.exp(z)

# Define the coordinates
x = np.linspace(0, 2*np.pi, 10)
y = np.linspace(0, np.pi, 10)
z = np.linspace(0, 1, 10)

# Compute the gradient
grad = np.gradient(f(x, y, z))

# Print the gradient
print("Gradient of f:")
print("df/dx =", grad[0])
print("df/dy =", grad[1])
print("df/dz =", grad[2])

import numpy as np
# Create a row vector
row_vector = np.array([1, 2, 3])
print("Row vector: ", row_vector)
# Create a column vector
col_vector = np.array([[1], [2], [3]])
print("Column vector: \n", col_vector)

matrix = np.array([[1, 2], [3, 4]])
print("Matrix: \n", matrix)

# Transpose a row vector
transpose_row_vector = row_vector.T
print("Transpose of row vector: \n", transpose_row_vector)

# Transpose a matrix
transpose_matrix = matrix.T
print("Transpose of matrix: \n", transpose_matrix)

# Conjugate transpose a row vector
conj_trans_row_vector = row_vector.conj().T
print("Conjugate transpose of row vector: \n", conj_trans_row_vector)
# Conjugate transpose a matrix
conj_trans_matrix = matrix.conj().T
print("Conjugate transpose of matrix: \n", conj_trans_matrix)

import numpy as np
A = np.array([
[1, 2, 3, 4],
[5, 6, 7, 8],
[9, 10, 11, 12],
[13, 14, 15, 16]
])
# Generate the matrix into echelon form
# by solving for the matrix using np.linalg.solve
# with the augmented matrix as input
n_rows, n_cols = A.shape
for i in range(min(n_rows, n_cols)):
# Find the row with the largest absolute value in the i-th column
   max_row = np.argmax(np.abs(A[i:, i])) + i

# Swap the max row with the current row
   if i != max_row:
      A[[i, max_row]] = A[[max_row, i]]

# Perform row operations to get zeros below the leading coefficient
for j in range(i+1, n_rows):
  c = A[j, i] / A[i, i]
  A[j, i:] -= c * A[i, i:]

# Find the rank of the matrix by counting the number of non-zero rows
rank = np.sum([np.any(A[i]) for i in range(n_rows)])
print("Echelon form of A:\n", A)
print("Rank of A:", rank)

import numpy as np
A = np.array([
[2, -1, 0],
[0, 1, 2],
[1, 0, 1]
])
# Find the cofactors of A
n_rows, n_cols = A.shape
cofactors = np.zeros((n_rows, n_cols))
for i in range(n_rows):
  for j in range(n_cols):
     submatrix = np.delete(np.delete(A, i, axis=0), j, axis=1)
     minor = np.linalg.det(submatrix)
     cofactors[i, j] = (-1) ** (i+j) * minor
print("Cofactors of A:\n", cofactors)

# Find the determinant of A
det = np.linalg.det(A)
print("Determinant of A:", det)

# Find the adjoint of A
adj = cofactors.T
print("Adjoint of A:\n", adj)

# Find the inverse of A
inv = adj / det
print("Inverse of A:\n", inv)

#2a + 3y + z = 9
#a - y + 2z = 1
#3a + 4y + 2z = 15

import numpy as np
# Matrix of coefficients
A = np.array([
[2, 3, 1],
[1, -1, 2],
[3, 4, 2]
])

# Column vector of constants
b = np.array([
[9],
[1],
[15]
])

def gauss_elimination(A, b):
   n = A.shape[0]
   aug = np.concatenate((A, b), axis=1)

  # Forward elimination
   for i in range(n):
    pivot = aug[i, i]
   for j in range(i+1, n):
    factor = aug[j, i] / pivot
    aug[j, :] -= factor * aug[i, :]

# Back substitution
   x = np.zeros((n, 1))
   for i in range(n-1, -1, -1):
     x[i] = (aug[i, -1] - aug[i, :-1] @ x) / aug[i, i]
   return x

# Solve the system of equations
x = gauss_elimination(A, b)
print("Solution:")
print("x =", x[0])
print("y =", x[1])
print("z =", x[2])

import numpy as np
# Matrix of coefficients
A = np.array([
[2, 3, 1],
[1, -1, 2],
[3, 4, 2]
])

# Column vector of zeros
b = np.zeros((3, 1))
def gauss_jordan(A):
  n = A.shape[0]
  aug = np.concatenate((A, np.eye(n)), axis=1)

# Forward elimination
  for i in range(n):
    pivot = aug[i, i]
    aug[i, :] /= pivot
  for j in range(i+1, n):
    factor = aug[j, i]
    aug[j, :] -= factor * aug[i, :]

# Back substitution
  for i in range(n-1, -1, -1):
    for j in range(i-1, -1, -1):
      factor = aug[j, i]
      aug[j, :] -= factor * aug[i, :]
      return aug[:, n:]

# Solve the system of homogeneous equations
x = gauss_jordan(A)
print("Solutions:")
print("x =", x[0])
print("y =", x[1])
print("z =", x[2])

import numpy as np
A = np.array([
[1, 2, 1, 4],
[2, 4, 2, 8],
[3, 6, 3, 12]
])

# Find the basis of the column space
rref_A = np.around(np.linalg.inv(A.T @ A) @ A.T @ A, decimals=6)
basis_col_space = A[:, np.where(np.abs(rref_A) > 0)[1]]
print("Basis of column space:")
print(basis_col_space)


from scipy.linalg import null_space
# Find the basis of the null space
basis_null_space = null_space(A)
print("Basis of null space:")
print(basis_null_space)


# Find the basis of the row space
rref_A = np.around(np.linalg.inv(A.T @ A) @ A.T @ A, decimals=6)
basis_row_space = A[np.where(np.abs(rref_A) > 0)[0], :]
print("Basis of row space:")
print(basis_row_space)


# Find the basis of the left null space
basis_left_null_space = null_space(A.T)
print("Basis of left null space:")
print(basis_left_null_space)